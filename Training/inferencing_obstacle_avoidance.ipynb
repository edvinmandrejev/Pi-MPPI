{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "\n",
    "# import torch_optimizer as optim_custom\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from bernstein_torch import bernstein_coeff_order10_new\n",
    "import scipy.io as sio\n",
    "\n",
    "# from models.mlp_qp_vis_aware_2 import MLP, vis_aware_track_net, PointNet\n",
    "# import pol_matrix_comp\n",
    "# from tqdm import trange\n",
    "\n",
    "from mlp_obst_avoidance import MLP, mlp_projection_filter\n",
    "# from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Generating P matrix\n",
    "t_fin = 20.0\n",
    "num = 100\n",
    "tot_time = torch.linspace(0, t_fin, num)\n",
    "tot_time_copy = tot_time.reshape(num, 1)\n",
    "P, Pdot, Pddot = bernstein_coeff_order10_new(10, tot_time_copy[0], tot_time_copy[-1], tot_time_copy)\n",
    "P_diag = torch.block_diag(P, P)\n",
    "Pdot_diag = torch.block_diag(Pdot, Pdot)\n",
    "\n",
    "Pddot_diag = torch.block_diag(Pddot, Pddot)\n",
    "nvar = P.size(dim = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# data = loadmat(\"./dataset/data/train_data_2_500.mat\")\n",
    "data = np.load(\"./training_scripts/dataset/data/train_data_obs_150_100_250.npz\")\n",
    "\n",
    "# print(data)\n",
    "\n",
    "\n",
    "init_state = data['init_state_data']\n",
    "\n",
    "c_samples_input = data['c_samples_data']\n",
    "\n",
    "inp = np.hstack(( init_state, c_samples_input  ))\n",
    "\n",
    "\n",
    "\n",
    "inp_mean, inp_std = inp.mean(), inp.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "print(c_samples_input[0:5,0:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "# Differentiable Layer\n",
    "num_batch = 2\n",
    "\n",
    "P = P.to(device) \n",
    "Pdot = Pdot.to(device)\n",
    "P_diag = P_diag.to(device)\n",
    "Pdot_diag = Pdot_diag.to(device)\n",
    "\n",
    "Pddot_diag = Pddot_diag.to(device)\n",
    "\n",
    "\n",
    "\n",
    "num_dot = num \n",
    "num_ddot = num_dot \n",
    "num_constraint = 2*num+2*num_dot+2*num_ddot\n",
    "\n",
    "# CVAE input\n",
    "enc_inp_dim = np.shape(inp)[1] \n",
    "mlp_inp_dim = enc_inp_dim\n",
    "hidden_dim = 1024\n",
    "mlp_out_dim = 6*nvar#+3*num_constraint\n",
    "print(mlp_out_dim)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mlp =  MLP(mlp_inp_dim, hidden_dim, mlp_out_dim)\n",
    "model = mlp_projection_filter(P, Pdot, Pddot, mlp, num_batch, inp_mean, inp_std, t_fin).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"./training_scripts/weights/mlp_learned_proj_obs_150_100_250.pth\"))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# idx = np.random.randint(0, np.shape(inp)[0])\n",
    "idx = 100\n",
    "print(idx)\n",
    "\n",
    "\n",
    "\n",
    "inp_test = inp[idx]\n",
    "inp_test = torch.tensor(inp_test).float()\n",
    "inp_test = inp_test.to(device)\n",
    "inp_test = torch.vstack([inp_test] * num_batch)\n",
    "inp_norm = (inp_test - inp_mean) / inp_std\n",
    "\n",
    "init_state = inp_test[:, 0 : 6]\n",
    "\n",
    "c_samples_input_test = c_samples_input[idx]\n",
    "c_samples_input_test = torch.tensor(c_samples_input_test).float()\n",
    "c_samples_iniput_test = c_samples_input_test.to(device)\n",
    "c_samples_input_test = torch.vstack( [c_samples_input_test]*num_batch  )\n",
    "\n",
    "\n",
    "c_v_samples_input = c_samples_input_test[:, 0: nvar].to(device)\n",
    "c_pitch_samples_input = c_samples_input_test[:, nvar: 2*nvar].to(device)\n",
    "c_roll_samples_input = c_samples_input_test[:, 2*nvar: 3*nvar].to(device)    \n",
    "\n",
    "# print(inp_norm.device )\n",
    "\n",
    "# print(init_state.device )\n",
    "\n",
    "# print(c_v_samples_input.device )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    c_v_samples, c_pitch_samples, c_roll_samples, accumulated_res_fixed_point, accumulated_res_primal, accumulated_res_primal_temp, accumulated_res_fixed_point_temp = model.decoder_function(inp_norm, init_state, c_v_samples_input, c_pitch_samples_input, c_roll_samples_input)\n",
    "\n",
    "    accumulated_res_primal_temp = torch.stack(accumulated_res_primal_temp)[:, 0]\n",
    "    accumulated_res_fixed_point_temp = torch.stack(accumulated_res_fixed_point_temp)[:, 0]\n",
    "    \n",
    "\n",
    "\n",
    "    v_samples = torch.mm(model.P, c_v_samples.T).T \n",
    "\n",
    "    pitch_samples = torch.mm(model.P, c_pitch_samples.T).T\n",
    "\n",
    "    roll_samples =  torch.mm(model.P, c_roll_samples.T).T\n",
    "    \n",
    "    v_samples_input = torch.mm(model.P, c_v_samples_input.T).T \n",
    "\n",
    "    pitch_samples_input = torch.mm(model.P, c_pitch_samples_input.T).T\n",
    "\n",
    "    roll_samples_input =  torch.mm(model.P, c_roll_samples_input.T).T\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    plt.figure(4)\n",
    "    plt.plot(accumulated_res_primal_temp.cpu().detach().numpy())\n",
    "    \n",
    "    plt.figure(5)\n",
    "    plt.plot(accumulated_res_fixed_point_temp.cpu().detach().numpy())\n",
    "    \n",
    "    plt.figure(6)\n",
    "\n",
    "    plt.plot(v_samples.T.cpu().detach().numpy())\n",
    "    plt.plot(v_samples_input.T.cpu().detach().numpy(), '-b')\n",
    "    \n",
    "    \n",
    "    plt.figure(7)\n",
    "\n",
    "    plt.plot(pitch_samples.T.cpu().detach().numpy())\n",
    "    plt.plot(pitch_samples_input.T.cpu().detach().numpy(), '-b')\n",
    "    \n",
    "    plt.figure(8)\n",
    "\n",
    "    plt.plot(roll_samples.T.cpu().detach().numpy())\n",
    "    plt.plot(roll_samples_input.T.cpu().detach().numpy(), '-b') \n",
    "    \n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
