{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "current_working_directory = os.getcwd()\n",
    "print(current_working_directory)\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "\n",
    "# import torch_optimizer as optim_custom\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from bernstein_torch import bernstein_coeff_order10_new\n",
    "import scipy.io as sio\n",
    "\n",
    "# from models.mlp_qp_vis_aware_2 import MLP, vis_aware_track_net, PointNet\n",
    "# import pol_matrix_comp\n",
    "from tqdm import trange,tqdm\n",
    "\n",
    "from models.mlp_terrain import MLP, mlp_projection_filter\n",
    "# from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Generating P matrix\n",
    "t_fin = 20.0\n",
    "num = 100\n",
    "tot_time = torch.linspace(0, t_fin, num)\n",
    "tot_time_copy = tot_time.reshape(num, 1)\n",
    "P, Pdot, Pddot = bernstein_coeff_order10_new(10, tot_time_copy[0], tot_time_copy[-1], tot_time_copy)\n",
    "P_diag = torch.block_diag(P, P)\n",
    "Pdot_diag = torch.block_diag(Pdot, Pdot)\n",
    "\n",
    "Pddot_diag = torch.block_diag(Pddot, Pddot)\n",
    "nvar = P.size(dim = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "# data = loadmat(\"./dataset/data/train_data_2_500.mat\")\n",
    "data = np.load(\"./training_scripts/dataset/data/train_data_terrain_250_c2_v3.npz\")\n",
    "\n",
    "# print(data)\n",
    "\n",
    "\n",
    "init_state = data['init_state_data']\n",
    "\n",
    "c_samples_input = data['c_samples_data']\n",
    "\n",
    "print(init_state.shape)\n",
    "\n",
    "inp = np.hstack(( init_state, c_samples_input  ))\n",
    "\n",
    "\n",
    "\n",
    "inp_mean, inp_std = inp.mean(), inp.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Custom Dataset Loader \n",
    "class TrajDataset(Dataset):\n",
    "\t\"\"\"Expert Trajectory Dataset.\"\"\"\n",
    "\tdef __init__(self, inp, init_state, c_samples_input):\n",
    "\t\t\n",
    "\t\t# input\n",
    "\t\tself.inp = inp\n",
    "\t\t# State Data\n",
    "\t\tself.init_state = init_state\n",
    "\t\t\n",
    "\t\tself.c_samples_input = c_samples_input\n",
    "\t\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.inp)    \n",
    "\t\t\t\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\t\n",
    "\t\t# Inputs\n",
    "\t\tinit_state = self.init_state[idx]\n",
    "\t\t\n",
    "\t\tc_samples_input = self.c_samples_input[idx]\n",
    "  \n",
    "\t\tinp = self.inp[idx]\n",
    "\t\t\n",
    "\t\t\t\t \n",
    "\t\treturn torch.tensor(inp).float(), torch.tensor(init_state).float(), torch.tensor(c_samples_input).float() \n",
    "\n",
    "# Batch Size - 3k or 4k\n",
    "batch_size = 12000\n",
    "\n",
    "# Using PyTorch Dataloader\n",
    "train_dataset = TrajDataset(inp, init_state, c_samples_input)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "# Differentiable Layer\n",
    "num_batch = train_loader.batch_size\n",
    "\n",
    "P = P.to(device) \n",
    "Pdot = Pdot.to(device)\n",
    "P_diag = P_diag.to(device)\n",
    "Pdot_diag = Pdot_diag.to(device)\n",
    "\n",
    "Pddot_diag = Pddot_diag.to(device)\n",
    "\n",
    "\n",
    "\n",
    "num_dot = num \n",
    "num_ddot = num_dot \n",
    "num_constraint = 2*num+2*num_dot+2*num_ddot\n",
    "\n",
    "# CVAE input\n",
    "enc_inp_dim = np.shape(inp)[1] \n",
    "mlp_inp_dim = enc_inp_dim\n",
    "hidden_dim = 1024\n",
    "mlp_out_dim = 6*nvar#+3*num_constraint\n",
    "print(mlp_out_dim)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mlp =  MLP(mlp_inp_dim, hidden_dim, mlp_out_dim)\n",
    "model = mlp_projection_filter(P, Pdot, Pddot, mlp, num_batch, inp_mean, inp_std, t_fin).to(device)\n",
    "# model.load_state_dict(torch.load('./training_scripts/weights/mlp_learned_proj_terrain_250_c4_02_check_2.pth'))\n",
    "model.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "epochs = 50\n",
    "step, beta = 0, 1.0 # 3.5\n",
    "optimizer = optim.AdamW(model.parameters(), lr = 2e-4, weight_decay=6e-5)\n",
    "# optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 30, gamma = 0.1)\n",
    "losses = []\n",
    "last_loss = torch.inf\n",
    "model_checkpoint = 0\n",
    "avg_train_loss, avg_primal_loss, avg_fixed_point_loss = [], [], []\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # Train Loop\n",
    "    losses_train, primal_losses, fixed_point_losses = [], [], []\n",
    "    \n",
    "    for (inp, init_state, c_samples_input) in tqdm(train_loader):\n",
    "        \n",
    "        # Input and Output \n",
    "        inp = inp.to(device)\n",
    "        init_state = init_state.to(device)\n",
    "        c_samples_input = c_samples_input.to(device)\n",
    "        \n",
    "\n",
    "        c_v_samples_input = c_samples_input[:, 0: nvar]\n",
    "        c_pitch_samples_input = c_samples_input[:, nvar: 2*nvar]\n",
    "        c_roll_samples_input = c_samples_input[:, 2*nvar: 3*nvar]    \n",
    "\n",
    "        \n",
    "        c_v_samples, c_pitch_samples, c_roll_samples, accumulated_res_fixed_point, accumulated_res_primal, accumulated_res_primal_temp, accumulated_res_fixed_point_temp = model(inp, init_state, c_v_samples_input, c_pitch_samples_input, c_roll_samples_input)\n",
    "        primal_loss, fixed_point_loss, loss = model.mlp_loss(accumulated_res_primal, accumulated_res_fixed_point, c_v_samples, c_v_samples_input, c_pitch_samples, c_pitch_samples_input, c_roll_samples, c_roll_samples_input)\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses_train.append(loss.detach().cpu().numpy()) \n",
    "        primal_losses.append(primal_loss.detach().cpu().numpy())\n",
    "        fixed_point_losses.append(fixed_point_loss.detach().cpu().numpy())\n",
    "        \n",
    "\n",
    "    if epoch % 2 == 0:    \n",
    "        print(f\"Epoch: {epoch + 1}, Train Loss: {np.average(losses_train):.3f}, primal: {np.average(primal_losses):.3f}, fixed_point: {np.average(fixed_point_losses):.3f} \")\n",
    "\n",
    "    step += 0.07 #0.15\n",
    "    # scheduler.step()\n",
    "    if loss <= last_loss:\n",
    "            torch.save(model.state_dict(), f\"./training_scripts/weights/mlp_learned_proj_terrain_250_c2_05_v3_lowest.pth\")\n",
    "            last_loss = loss\n",
    "\n",
    "    if epoch % 15 == 0:\n",
    "        torch.save(model.state_dict(), f\"./training_scripts/weights/mlp_learned_proj_terrain_250_c2_05_v3_check_{model_checkpoint}.pth\")\n",
    "        model_checkpoint += 1\n",
    "        \n",
    "    avg_train_loss.append(np.average(losses_train)), avg_primal_loss.append(np.average(primal_losses)), \\\n",
    "    avg_fixed_point_loss.append(np.average(fixed_point_losses))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './training_scripts/weights/mlp_learned_proj_terrain_250_c2_05_v3.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "h_avg_train_loss = np.array(avg_train_loss)\n",
    "h_avg_primal_loss = np.array(avg_primal_loss)\n",
    "h_avg_fixed_point_loss = np.array(avg_fixed_point_loss)\n",
    "h_mean = inp_mean\n",
    "h_std = inp_std\n",
    "np.savez(\"./training_scripts/weights/data_out_terrain_250_c2_05_v3\",avg_train_loss=h_avg_train_loss,avg_primal_loss=h_avg_primal_loss,\n",
    "avg_fixed_point_loss=h_avg_fixed_point_loss,mean=h_mean,std=h_std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
